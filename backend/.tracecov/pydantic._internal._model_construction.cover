    1: """Private logic for creating models."""
       
    1: from __future__ import annotations as _annotations
       
    1: import operator
    1: import sys
    1: import typing
    1: import warnings
    1: import weakref
    1: from abc import ABCMeta
    1: from functools import cache, partial, wraps
    1: from types import FunctionType
    1: from typing import TYPE_CHECKING, Any, Callable, Generic, Literal, NoReturn, TypeVar, cast
       
    1: from pydantic_core import PydanticUndefined, SchemaSerializer
    1: from typing_extensions import TypeAliasType, dataclass_transform, deprecated, get_args, get_origin
    1: from typing_inspection import typing_objects
       
    1: from ..errors import PydanticUndefinedAnnotation, PydanticUserError
    1: from ..plugin._schema_validator import create_schema_validator
    1: from ..warnings import GenericBeforeBaseModelWarning, PydanticDeprecatedSince20
    1: from ._config import ConfigWrapper
    1: from ._decorators import DecoratorInfos, PydanticDescriptorProxy, get_attribute_from_bases, unwrap_wrapped_function
    1: from ._fields import collect_model_fields, is_valid_field_name, is_valid_privateattr_name, rebuild_model_fields
    1: from ._generate_schema import GenerateSchema, InvalidSchemaError
    1: from ._generics import PydanticGenericMetadata, get_model_typevars_map
    1: from ._import_utils import import_cached_base_model, import_cached_field_info
    1: from ._mock_val_ser import set_model_mocks
    1: from ._namespace_utils import NsResolver
    1: from ._signature import generate_pydantic_signature
    1: from ._typing_extra import (
           _make_forward_ref,
           eval_type_backport,
           is_classvar_annotation,
           parent_frame_namespace,
       )
    1: from ._utils import LazyClassAttribute, SafeGetItemProxy
       
    1: if TYPE_CHECKING:
>>>>>>     from ..fields import Field as PydanticModelField
>>>>>>     from ..fields import FieldInfo, ModelPrivateAttr
>>>>>>     from ..fields import PrivateAttr as PydanticModelPrivateAttr
>>>>>>     from ..main import BaseModel
       else:
    1:     PydanticModelField = object()
    1:     PydanticModelPrivateAttr = object()
       
    1: object_setattr = object.__setattr__
       
       
    2: class _ModelNamespaceDict(dict):
    1:     """A dictionary subclass that intercepts attribute setting on model classes and
           warns about overriding of decorators.
           """
       
    1:     def __setitem__(self, k: str, v: object) -> None:
 1340:         existing: Any = self.get(k, None)
 1340:         if existing and v is not existing and isinstance(existing, PydanticDescriptorProxy):
>>>>>>             warnings.warn(
>>>>>>                 f'`{k}` overrides an existing Pydantic `{existing.decorator_info.decorator_repr}` decorator',
>>>>>>                 stacklevel=2,
                   )
       
 1340:         return super().__setitem__(k, v)
       
       
    6: def NoInitField(
           *,
    2:     init: Literal[False] = False,
    1: ) -> Any:
           """Only for typing purposes. Used as default value of `__pydantic_fields_set__`,
           `__pydantic_extra__`, `__pydantic_private__`, so they could be ignored when
           synthesizing the `__init__` signature.
           """
       
       
       # For ModelMetaclass.register():
    1: _T = TypeVar('_T')
       
       
    3: @dataclass_transform(kw_only_default=True, field_specifiers=(PydanticModelField, PydanticModelPrivateAttr, NoInitField))
    2: class ModelMetaclass(ABCMeta):
    9:     def __new__(
               mcs,
    1:         cls_name: str,
    1:         bases: tuple[type[Any], ...],
    1:         namespace: dict[str, Any],
    2:         __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
    2:         __pydantic_reset_parent_namespace__: bool = True,
    2:         _create_model_module: str | None = None,
    1:         **kwargs: Any,
    1:     ) -> type:
               """Metaclass for creating Pydantic models.
       
               Args:
                   cls_name: The name of the class to be created.
                   bases: The base classes of the class to be created.
                   namespace: The attribute dictionary of the class to be created.
                   __pydantic_generic_metadata__: Metadata for generic models.
                   __pydantic_reset_parent_namespace__: Reset parent namespace.
                   _create_model_module: The module of the class to be created, if created by `create_model`.
                   **kwargs: Catch-all for any other keyword arguments.
       
               Returns:
                   The new class created by the metaclass.
               """
               # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
               # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
               # call we're in the middle of is for the `BaseModel` class.
  103:         if bases:
                   raw_annotations: dict[str, Any]
  102:             if sys.version_info >= (3, 14):
                       if (
>>>>>>                     '__annotations__' in namespace
                       ):  # `from __future__ import annotations` was used in the model's module
>>>>>>                     raw_annotations = namespace['__annotations__']
                       else:
                           # See https://docs.python.org/3.14/library/annotationlib.html#using-annotations-in-a-metaclass:
>>>>>>                     from annotationlib import Format, call_annotate_function, get_annotate_from_class_namespace
       
>>>>>>                     if annotate := get_annotate_from_class_namespace(namespace):
>>>>>>                         raw_annotations = call_annotate_function(annotate, format=Format.FORWARDREF)
                           else:
>>>>>>                         raw_annotations = {}
                   else:
  102:                 raw_annotations = namespace.get('__annotations__', {})
       
  102:             base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
       
  102:             config_wrapper = ConfigWrapper.for_model(bases, namespace, raw_annotations, kwargs)
  102:             namespace['model_config'] = config_wrapper.config_dict
  204:             private_attributes = inspect_namespace(
  102:                 namespace, raw_annotations, config_wrapper.ignored_types, class_vars, base_field_names
                   )
  102:             if private_attributes or base_private_attributes:
    1:                 original_model_post_init = get_model_post_init(namespace, bases)
    1:                 if original_model_post_init is not None:
                           # if there are private_attributes and a model_post_init function, we handle both
       
>>>>>>                     @wraps(original_model_post_init)
>>>>>>                     def wrapped_model_post_init(self: BaseModel, context: Any, /) -> None:
                               """We need to both initialize private attributes and call the user-defined model_post_init
                               method.
                               """
>>>>>>                         init_private_attributes(self, context)
>>>>>>                         original_model_post_init(self, context)
       
>>>>>>                     namespace['model_post_init'] = wrapped_model_post_init
                       else:
    1:                     namespace['model_post_init'] = init_private_attributes
       
  102:             namespace['__class_vars__'] = class_vars
  102:             namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
       
  102:             cls = cast('type[BaseModel]', super().__new__(mcs, cls_name, bases, namespace, **kwargs))
  102:             BaseModel_ = import_cached_base_model()
       
  102:             mro = cls.__mro__
  102:             if Generic in mro and mro.index(Generic) < mro.index(BaseModel_):
>>>>>>                 warnings.warn(
>>>>>>                     GenericBeforeBaseModelWarning(
>>>>>>                         'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                               'for pydantic generics to work properly.'
                           ),
>>>>>>                     stacklevel=2,
                       )
       
  102:             cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
  102:             cls.__pydantic_post_init__ = (
  102:                 None if cls.model_post_init is BaseModel_.model_post_init else 'model_post_init'
                   )
       
  102:             cls.__pydantic_setattr_handlers__ = {}
       
  102:             cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
  102:             cls.__pydantic_decorators__.update_from_config(config_wrapper)
       
                   # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
  102:             if __pydantic_generic_metadata__:
>>>>>>                 cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
                   else:
  102:                 parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
  102:                 parameters = getattr(cls, '__parameters__', None) or parent_parameters
  102:                 if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
>>>>>>                     from ..root_model import RootModelRootType
       
>>>>>>                     missing_parameters = tuple(x for x in parameters if x not in parent_parameters)
>>>>>>                     if RootModelRootType in parent_parameters and RootModelRootType not in parameters:
                               # This is a special case where the user has subclassed `RootModel`, but has not parametrized
                               # RootModel with the generic type identifiers being used. Ex:
                               # class MyModel(RootModel, Generic[T]):
                               #    root: T
                               # Should instead just be:
                               # class MyModel(RootModel[T]):
                               #   root: T
>>>>>>                         parameters_str = ', '.join([x.__name__ for x in missing_parameters])
>>>>>>                         error_message = (
>>>>>>                             f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '
>>>>>>                             f'{parameters_str} in its parameters. '
>>>>>>                             f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'
                               )
                           else:
>>>>>>                         combined_parameters = parent_parameters + missing_parameters
>>>>>>                         parameters_str = ', '.join([str(x) for x in combined_parameters])
>>>>>>                         generic_type_label = f'typing.Generic[{parameters_str}]'
>>>>>>                         error_message = (
>>>>>>                             f'All parameters must be present on typing.Generic;'
>>>>>>                             f' you should inherit from {generic_type_label}.'
                               )
>>>>>>                         if Generic not in bases:  # pragma: no cover
                                   # We raise an error here not because it is desirable, but because some cases are mishandled.
                                   # It would be nice to remove this error and still have things behave as expected, it's just
                                   # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                                   # and not returning a typing._GenericAlias from it.
>>>>>>                             bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
>>>>>>                             error_message += (
>>>>>>                                 f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                                   )
>>>>>>                     raise TypeError(error_message)
       
  102:                 cls.__pydantic_generic_metadata__ = {
  102:                     'origin': None,
  102:                     'args': (),
  102:                     'parameters': parameters,
                       }
       
  102:             cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
       
                   # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
                   # for attributes not in `new_namespace` (e.g. private attributes)
  106:             for name, obj in private_attributes.items():
    4:                 obj.__set_name__(cls, name)
       
  102:             if __pydantic_reset_parent_namespace__:
   94:                 cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
  102:             parent_namespace: dict[str, Any] | None = getattr(cls, '__pydantic_parent_namespace__', None)
  102:             if isinstance(parent_namespace, dict):
>>>>>>                 parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
       
  102:             ns_resolver = NsResolver(parent_namespace=parent_namespace)
       
  102:             set_model_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)
       
                   # This is also set in `complete_model_class()`, after schema gen because they are recreated.
                   # We set them here as well for backwards compatibility:
  204:             cls.__pydantic_computed_fields__ = {
  204:                 k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()
                   }
       
  102:             if config_wrapper.defer_build:
>>>>>>                 set_model_mocks(cls)
                   else:
                       # Any operation that requires accessing the field infos instances should be put inside
                       # `complete_model_class()`:
  204:                 complete_model_class(
  102:                     cls,
  102:                     config_wrapper,
  102:                     ns_resolver,
  102:                     raise_errors=False,
  102:                     create_model_module=_create_model_module,
                       )
       
  102:             if config_wrapper.frozen and '__hash__' not in namespace:
>>>>>>                 set_default_hash_func(cls, bases)
       
                   # using super(cls, cls) on the next line ensures we only call the parent class's __pydantic_init_subclass__
                   # I believe the `type: ignore` is only necessary because mypy doesn't realize that this code branch is
                   # only hit for _proper_ subclasses of BaseModel
  102:             super(cls, cls).__pydantic_init_subclass__(**kwargs)  # type: ignore[misc]
  102:             return cls
               else:
                   # These are instance variables, but have been assigned to `NoInitField` to trick the type checker.
    4:             for instance_slot in '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__':
    6:                 namespace.pop(
    3:                     instance_slot,
    3:                     None,  # In case the metaclass is used with a class other than `BaseModel`.
                       )
    1:             namespace.get('__annotations__', {}).clear()
    1:             return super().__new__(mcs, cls_name, bases, namespace, **kwargs)
       
    1:     if not TYPE_CHECKING:  # pragma: no branch
               # We put `__getattr__` in a non-TYPE_CHECKING block because otherwise, mypy allows arbitrary attribute access
       
    1:         def __getattr__(self, item: str) -> Any:
                   """This is necessary to keep attribute access working for class attribute access."""
 2239:             private_attributes = self.__dict__.get('__private_attributes__')
 2239:             if private_attributes and item in private_attributes:
    4:                 return private_attributes[item]
 2235:             raise AttributeError(item)
       
    2:     @classmethod
    2:     def __prepare__(cls, *args: Any, **kwargs: Any) -> dict[str, object]:
  103:         return _ModelNamespaceDict()
       
           # Due to performance and memory issues, in the ABCMeta.__subclasscheck__ implementation, we don't support
           # registered virtual subclasses. See https://github.com/python/cpython/issues/92810#issuecomment-2762454345.
           # This may change once the CPython gets fixed (possibly in 3.15), in which case we should conditionally
           # define `register()`.
    1:     def register(self, subclass: type[_T]) -> type[_T]:
>>>>>>         warnings.warn(
>>>>>>             f"For performance reasons, virtual subclasses registered using '{self.__qualname__}.register()' "
                   "are not supported in 'isinstance()' and 'issubclass()' checks.",
>>>>>>             stacklevel=2,
               )
>>>>>>         return super().register(subclass)
       
    1:     __instancecheck__ = type.__instancecheck__  # pyright: ignore[reportAssignmentType]
    1:     __subclasscheck__ = type.__subclasscheck__  # pyright: ignore[reportAssignmentType]
       
    2:     @staticmethod
    2:     def _collect_bases_data(bases: tuple[type[Any], ...]) -> tuple[set[str], set[str], dict[str, ModelPrivateAttr]]:
  102:         BaseModel = import_cached_base_model()
       
  102:         field_names: set[str] = set()
  102:         class_vars: set[str] = set()
  102:         private_attributes: dict[str, ModelPrivateAttr] = {}
  205:         for base in bases:
  103:             if issubclass(base, BaseModel) and base is not BaseModel:
                       # model_fields might not be defined yet in the case of generics, so we use getattr here:
   34:                 field_names.update(getattr(base, '__pydantic_fields__', {}).keys())
   34:                 class_vars.update(base.__class_vars__)
   34:                 private_attributes.update(base.__private_attributes__)
  102:         return field_names, class_vars, private_attributes
       
    2:     @property
    3:     @deprecated(
    1:         'The `__fields__` attribute is deprecated, use the `model_fields` class property instead.', category=None
           )
    2:     def __fields__(self) -> dict[str, FieldInfo]:
>>>>>>         warnings.warn(
>>>>>>             'The `__fields__` attribute is deprecated, use the `model_fields` class property instead.',
>>>>>>             PydanticDeprecatedSince20,
>>>>>>             stacklevel=2,
               )
>>>>>>         return getattr(self, '__pydantic_fields__', {})
       
    2:     @property
    2:     def __pydantic_fields_complete__(self) -> bool:
               """Whether the fields where successfully collected (i.e. type hints were successfully resolves).
       
               This is a private attribute, not meant to be used outside Pydantic.
               """
  241:         if '__pydantic_fields__' not in self.__dict__:
>>>>>>             return False
       
  241:         field_infos = cast('dict[str, FieldInfo]', self.__pydantic_fields__)  # pyright: ignore[reportAttributeAccessIssue]
       
 1900:         return all(field_info._complete for field_info in field_infos.values())
       
    1:     def __dir__(self) -> list[str]:
>>>>>>         attributes = list(super().__dir__())
>>>>>>         if '__fields__' in attributes:
>>>>>>             attributes.remove('__fields__')
>>>>>>         return attributes
       
       
    1: def init_private_attributes(self: BaseModel, context: Any, /) -> None:
           """This function is meant to behave like a BaseModel method to initialise private attributes.
       
           It takes context as an argument since that's what pydantic-core passes when calling it.
       
           Args:
               self: The BaseModel instance.
               context: The context.
           """
>>>>>>     if getattr(self, '__pydantic_private__', None) is None:
>>>>>>         pydantic_private = {}
>>>>>>         for name, private_attr in self.__private_attributes__.items():
>>>>>>             default = private_attr.get_default()
>>>>>>             if default is not PydanticUndefined:
>>>>>>                 pydantic_private[name] = default
>>>>>>         object_setattr(self, '__pydantic_private__', pydantic_private)
       
       
    1: def get_model_post_init(namespace: dict[str, Any], bases: tuple[type[Any], ...]) -> Callable[..., Any] | None:
           """Get the `model_post_init` method from the namespace or the class bases, or `None` if not defined."""
    1:     if 'model_post_init' in namespace:
>>>>>>         return namespace['model_post_init']
       
    1:     BaseModel = import_cached_base_model()
       
    1:     model_post_init = get_attribute_from_bases(bases, 'model_post_init')
    1:     if model_post_init is not BaseModel.model_post_init:
>>>>>>         return model_post_init
       
       
    7: def inspect_namespace(  # noqa C901
    1:     namespace: dict[str, Any],
    1:     raw_annotations: dict[str, Any],
    1:     ignored_types: tuple[type[Any], ...],
    1:     base_class_vars: set[str],
    1:     base_class_fields: set[str],
    1: ) -> dict[str, ModelPrivateAttr]:
           """Iterate over the namespace and:
           * gather private attributes
           * check for items which look like fields but are not (e.g. have no annotation) and warn.
       
           Args:
               namespace: The attribute dictionary of the class to be created.
               raw_annotations: The (non-evaluated) annotations of the model.
               ignored_types: A tuple of ignore types.
               base_class_vars: A set of base class class variables.
               base_class_fields: A set of base class fields.
       
           Returns:
               A dict contains private attributes info.
       
           Raises:
               TypeError: If there is a `__root__` field in model.
               NameError: If private attribute name is invalid.
               PydanticUserError:
                   - If a field does not have a type annotation.
                   - If a field on base class was overridden by a non-annotated attribute.
           """
  102:     from ..fields import ModelPrivateAttr, PrivateAttr
       
  102:     FieldInfo = import_cached_field_info()
       
  102:     all_ignored_types = ignored_types + default_ignored_types()
       
  102:     private_attributes: dict[str, ModelPrivateAttr] = {}
       
  102:     if '__root__' in raw_annotations or '__root__' in namespace:
>>>>>>         raise TypeError("To define root models, use `pydantic.RootModel` rather than a field called '__root__'")
       
  102:     ignored_names: set[str] = set()
 1208:     for var_name, value in list(namespace.items()):
 1106:         if var_name == 'model_config' or var_name == '__pydantic_extra__':
  103:             continue
               elif (
 1003:             isinstance(value, type)
    1:             and value.__module__ == namespace['__module__']
    1:             and '__qualname__' in namespace
    1:             and value.__qualname__.startswith(f'{namespace["__qualname__"]}.')
               ):
                   # `value` is a nested type defined in this namespace; don't error
    1:             continue
 1002:         elif isinstance(value, all_ignored_types) or value.__class__.__module__ == 'functools':
   39:             ignored_names.add(var_name)
   39:             continue
  963:         elif isinstance(value, ModelPrivateAttr):
    4:             if var_name.startswith('__'):
>>>>>>                 raise NameError(
>>>>>>                     'Private attributes must not use dunder names;'
>>>>>>                     f' use a single underscore prefix instead of {var_name!r}.'
                       )
    4:             elif is_valid_field_name(var_name):
>>>>>>                 raise NameError(
>>>>>>                     'Private attributes must not use valid field names;'
>>>>>>                     f' use sunder names, e.g. {"_" + var_name!r} instead of {var_name!r}.'
                       )
    4:             private_attributes[var_name] = value
    4:             del namespace[var_name]
  959:         elif isinstance(value, FieldInfo) and not is_valid_field_name(var_name):
>>>>>>             suggested_name = var_name.lstrip('_') or 'my_field'  # don't suggest '' for all-underscore name
>>>>>>             raise NameError(
>>>>>>                 f'Fields must not use names with leading underscores;'
>>>>>>                 f' e.g., use {suggested_name!r} instead of {var_name!r}.'
                   )
       
  959:         elif var_name.startswith('__'):
  545:             continue
  414:         elif is_valid_privateattr_name(var_name):
>>>>>>             if var_name not in raw_annotations or not is_classvar_annotation(raw_annotations[var_name]):
>>>>>>                 private_attributes[var_name] = cast(ModelPrivateAttr, PrivateAttr(default=value))
>>>>>>                 del namespace[var_name]
  414:         elif var_name in base_class_vars:
>>>>>>             continue
  414:         elif var_name not in raw_annotations:
>>>>>>             if var_name in base_class_fields:
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'Field {var_name!r} defined on a base class was overridden by a non-annotated attribute. '
                           f'All field definitions, including overrides, require a type annotation.',
>>>>>>                     code='model-field-overridden',
                       )
>>>>>>             elif isinstance(value, FieldInfo):
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'Field {var_name!r} requires a type annotation', code='model-field-missing-annotation'
                       )
                   else:
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'A non-annotated attribute was detected: `{var_name} = {value!r}`. All model fields require a '
>>>>>>                     f'type annotation; if `{var_name}` is not meant to be a field, you may be able to resolve this '
                           f"error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.",
>>>>>>                     code='model-field-missing-annotation',
                       )
       
  691:     for ann_name, ann_type in raw_annotations.items():
               if (
  589:             is_valid_privateattr_name(ann_name)
    4:             and ann_name not in private_attributes
>>>>>>             and ann_name not in ignored_names
                   # This condition can be a false negative when `ann_type` is stringified,
                   # but it is handled in most cases in `set_model_fields`:
>>>>>>             and not is_classvar_annotation(ann_type)
>>>>>>             and ann_type not in all_ignored_types
>>>>>>             and getattr(ann_type, '__module__', None) != 'functools'
               ):
>>>>>>             if isinstance(ann_type, str):
                       # Walking up the frames to get the module namespace where the model is defined
                       # (as the model class wasn't created yet, we unfortunately can't use `cls.__module__`):
>>>>>>                 frame = sys._getframe(2)
>>>>>>                 if frame is not None:
>>>>>>                     try:
>>>>>>                         ann_type = eval_type_backport(
>>>>>>                             _make_forward_ref(ann_type, is_argument=False, is_class=True),
>>>>>>                             globalns=frame.f_globals,
>>>>>>                             localns=frame.f_locals,
                               )
>>>>>>                     except (NameError, TypeError):
>>>>>>                         pass
       
>>>>>>             if typing_objects.is_annotated(get_origin(ann_type)):
>>>>>>                 _, *metadata = get_args(ann_type)
>>>>>>                 private_attr = next((v for v in metadata if isinstance(v, ModelPrivateAttr)), None)
>>>>>>                 if private_attr is not None:
>>>>>>                     private_attributes[ann_name] = private_attr
>>>>>>                     continue
>>>>>>             private_attributes[ann_name] = PrivateAttr()
       
  102:     return private_attributes
       
       
    1: def set_default_hash_func(cls: type[BaseModel], bases: tuple[type[Any], ...]) -> None:
>>>>>>     base_hash_func = get_attribute_from_bases(bases, '__hash__')
>>>>>>     new_hash_func = make_hash_func(cls)
>>>>>>     if base_hash_func in {None, object.__hash__} or getattr(base_hash_func, '__code__', None) == new_hash_func.__code__:
               # If `__hash__` is some default, we generate a hash function.
               # It will be `None` if not overridden from BaseModel.
               # It may be `object.__hash__` if there is another
               # parent class earlier in the bases which doesn't override `__hash__` (e.g. `typing.Generic`).
               # It may be a value set by `set_default_hash_func` if `cls` is a subclass of another frozen model.
               # In the last case we still need a new hash function to account for new `model_fields`.
>>>>>>         cls.__hash__ = new_hash_func
       
       
    1: def make_hash_func(cls: type[BaseModel]) -> Any:
>>>>>>     getter = operator.itemgetter(*cls.__pydantic_fields__.keys()) if cls.__pydantic_fields__ else lambda _: 0
       
>>>>>>     def hash_func(self: Any) -> int:
>>>>>>         try:
>>>>>>             return hash(getter(self.__dict__))
>>>>>>         except KeyError:
                   # In rare cases (such as when using the deprecated copy method), the __dict__ may not contain
                   # all model fields, which is how we can get here.
                   # getter(self.__dict__) is much faster than any 'safe' method that accounts for missing keys,
                   # and wrapping it in a `try` doesn't slow things down much in the common case.
>>>>>>             return hash(getter(SafeGetItemProxy(self.__dict__)))
       
>>>>>>     return hash_func
       
       
    5: def set_model_fields(
    1:     cls: type[BaseModel],
    1:     config_wrapper: ConfigWrapper,
    1:     ns_resolver: NsResolver | None,
    1: ) -> None:
           """Collect and set `cls.__pydantic_fields__` and `cls.__class_vars__`.
       
           Args:
               cls: BaseModel or dataclass.
               config_wrapper: The config wrapper instance.
               ns_resolver: Namespace resolver to use when getting model annotations.
           """
  102:     typevars_map = get_model_typevars_map(cls)
  102:     fields, class_vars = collect_model_fields(cls, config_wrapper, ns_resolver, typevars_map=typevars_map)
       
  102:     cls.__pydantic_fields__ = fields
  102:     cls.__class_vars__.update(class_vars)
       
  102:     for k in class_vars:
               # Class vars should not be private attributes
               #     We remove them _here_ and not earlier because we rely on inspecting the class to determine its classvars,
               #     but private attributes are determined by inspecting the namespace _prior_ to class creation.
               #     In the case that a classvar with a leading-'_' is defined via a ForwardRef (e.g., when using
               #     `__future__.annotations`), we want to remove the private attribute which was detected _before_ we knew it
               #     evaluated to a classvar
       
>>>>>>         value = cls.__private_attributes__.pop(k, None)
>>>>>>         if value is not None and value.default is not PydanticUndefined:
>>>>>>             setattr(cls, k, value.default)
       
       
    8: def complete_model_class(
    1:     cls: type[BaseModel],
    1:     config_wrapper: ConfigWrapper,
    1:     ns_resolver: NsResolver,
           *,
    2:     raise_errors: bool = True,
    2:     call_on_complete_hook: bool = True,
    2:     create_model_module: str | None = None,
    1: ) -> bool:
           """Finish building a model class.
       
           This logic must be called after class has been created since validation functions must be bound
           and `get_type_hints` requires a class object.
       
           Args:
               cls: BaseModel or dataclass.
               config_wrapper: The config wrapper instance.
               ns_resolver: The namespace resolver instance to use during schema building.
               raise_errors: Whether to raise errors.
               call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.
               create_model_module: The module of the class to be created, if created by `create_model`.
       
           Returns:
               `True` if the model is successfully completed, else `False`.
       
           Raises:
               PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                   and `raise_errors=True`.
           """
  105:     typevars_map = get_model_typevars_map(cls)
       
  105:     if not cls.__pydantic_fields_complete__:
               # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.
               # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.
               # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete
               # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the
               # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`
               # when `__pydantic_complete__` is `True`, we rebuild here:
    6:         try:
   12:             cls.__pydantic_fields__ = rebuild_model_fields(
    6:                 cls,
    6:                 config_wrapper=config_wrapper,
    6:                 ns_resolver=ns_resolver,
    6:                 typevars_map=typevars_map,
                   )
    3:         except NameError as e:
    3:             exc = PydanticUndefinedAnnotation.from_name_error(e)
    3:             set_model_mocks(cls, f'`{exc.name}`')
    3:             if raise_errors:
>>>>>>                 raise exc from e
       
    6:         if not raise_errors and not cls.__pydantic_fields_complete__:
                   # No need to continue with schema gen, it is guaranteed to fail
    3:             return False
       
    3:         assert cls.__pydantic_fields_complete__
       
  204:     gen_schema = GenerateSchema(
  102:         config_wrapper,
  102:         ns_resolver,
  102:         typevars_map,
           )
       
  102:     try:
  102:         schema = gen_schema.generate_schema(cls)
    3:     except PydanticUndefinedAnnotation as e:
    3:         if raise_errors:
>>>>>>             raise
    3:         set_model_mocks(cls, f'`{e.name}`')
    3:         return False
       
   99:     core_config = config_wrapper.core_config(title=cls.__name__)
       
   99:     try:
   99:         schema = gen_schema.clean_schema(schema)
>>>>>>     except InvalidSchemaError:
>>>>>>         set_model_mocks(cls)
>>>>>>         return False
       
           # This needs to happen *after* model schema generation, as the return type
           # of the properties are evaluated and the `ComputedFieldInfo` are recreated:
   99:     cls.__pydantic_computed_fields__ = {k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()}
       
   99:     set_deprecated_descriptors(cls)
       
   99:     cls.__pydantic_core_schema__ = schema
       
  198:     cls.__pydantic_validator__ = create_schema_validator(
   99:         schema,
   99:         cls,
   99:         create_model_module or cls.__module__,
   99:         cls.__qualname__,
   99:         'create_model' if create_model_module else 'BaseModel',
   99:         core_config,
   99:         config_wrapper.plugin_settings,
           )
   99:     cls.__pydantic_serializer__ = SchemaSerializer(schema, core_config)
       
           # set __signature__ attr only for model class, but not for its instances
           # (because instances can define `__call__`, and `inspect.signature` shouldn't
           # use the `__signature__` attribute and instead generate from `__call__`).
  198:     cls.__signature__ = LazyClassAttribute(
   99:         '__signature__',
  198:         partial(
   99:             generate_pydantic_signature,
   99:             init=cls.__init__,
   99:             fields=cls.__pydantic_fields__,
   99:             validate_by_name=config_wrapper.validate_by_name,
   99:             extra=config_wrapper.extra,
               ),
           )
       
   99:     cls.__pydantic_complete__ = True
       
   99:     if call_on_complete_hook:
   99:         cls.__pydantic_on_complete__()
       
   99:     return True
       
       
    1: def set_deprecated_descriptors(cls: type[BaseModel]) -> None:
           """Set data descriptors on the class for deprecated fields."""
  691:     for field, field_info in cls.__pydantic_fields__.items():
  592:         if (msg := field_info.deprecation_message) is not None:
    1:             desc = _DeprecatedFieldDescriptor(msg)
    1:             desc.__set_name__(cls, field)
    1:             setattr(cls, field, desc)
       
   99:     for field, computed_field_info in cls.__pydantic_computed_fields__.items():
               if (
>>>>>>             (msg := computed_field_info.deprecation_message) is not None
                   # Avoid having two warnings emitted:
>>>>>>             and not hasattr(unwrap_wrapped_function(computed_field_info.wrapped_property), '__deprecated__')
               ):
>>>>>>             desc = _DeprecatedFieldDescriptor(msg, computed_field_info.wrapped_property)
>>>>>>             desc.__set_name__(cls, field)
>>>>>>             setattr(cls, field, desc)
       
       
    2: class _DeprecatedFieldDescriptor:
    1:     """Read-only data descriptor used to emit a runtime deprecation warning before accessing a deprecated field.
       
           Attributes:
               msg: The deprecation message to be emitted.
               wrapped_property: The property instance if the deprecated field is a computed field, or `None`.
               field_name: The name of the field being deprecated.
           """
       
    1:     field_name: str
       
    1:     def __init__(self, msg: str, wrapped_property: property | None = None) -> None:
    1:         self.msg = msg
    1:         self.wrapped_property = wrapped_property
       
    1:     def __set_name__(self, cls: type[BaseModel], name: str) -> None:
    1:         self.field_name = name
       
    1:     def __get__(self, obj: BaseModel | None, obj_type: type[BaseModel] | None = None) -> Any:
>>>>>>         if obj is None:
>>>>>>             if self.wrapped_property is not None:
>>>>>>                 return self.wrapped_property.__get__(None, obj_type)
>>>>>>             raise AttributeError(self.field_name)
       
>>>>>>         warnings.warn(self.msg, DeprecationWarning, stacklevel=2)
       
>>>>>>         if self.wrapped_property is not None:
>>>>>>             return self.wrapped_property.__get__(obj, obj_type)
>>>>>>         return obj.__dict__[self.field_name]
       
           # Defined to make it a data descriptor and take precedence over the instance's dictionary.
           # Note that it will not be called when setting a value on a model instance
           # as `BaseModel.__setattr__` is defined and takes priority.
    1:     def __set__(self, obj: Any, value: Any) -> NoReturn:
>>>>>>         raise AttributeError(self.field_name)
       
       
    2: class _PydanticWeakRef:
    1:     """Wrapper for `weakref.ref` that enables `pickle` serialization.
       
           Cloudpickle fails to serialize `weakref.ref` objects due to an arcane error related
           to abstract base classes (`abc.ABC`). This class works around the issue by wrapping
           `weakref.ref` instead of subclassing it.
       
           See https://github.com/pydantic/pydantic/issues/6763 for context.
       
           Semantics:
               - If not pickled, behaves the same as a `weakref.ref`.
               - If pickled along with the referenced object, the same `weakref.ref` behavior
                 will be maintained between them after unpickling.
               - If pickled without the referenced object, after unpickling the underlying
                 reference will be cleared (`__call__` will always return `None`).
           """
       
    1:     def __init__(self, obj: Any):
>>>>>>         if obj is None:
                   # The object will be `None` upon deserialization if the serialized weakref
                   # had lost its underlying object.
>>>>>>             self._wr = None
               else:
>>>>>>             self._wr = weakref.ref(obj)
       
    1:     def __call__(self) -> Any:
>>>>>>         if self._wr is None:
>>>>>>             return None
               else:
>>>>>>             return self._wr()
       
    1:     def __reduce__(self) -> tuple[Callable, tuple[weakref.ReferenceType | None]]:
>>>>>>         return _PydanticWeakRef, (self(),)
       
       
    1: def build_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:
           """Takes an input dictionary, and produces a new value that (invertibly) replaces the values with weakrefs.
       
           We can't just use a WeakValueDictionary because many types (including int, str, etc.) can't be stored as values
           in a WeakValueDictionary.
       
           The `unpack_lenient_weakvaluedict` function can be used to reverse this operation.
           """
   94:     if d is None:
   94:         return None
>>>>>>     result = {}
>>>>>>     for k, v in d.items():
>>>>>>         try:
>>>>>>             proxy = _PydanticWeakRef(v)
>>>>>>         except TypeError:
>>>>>>             proxy = v
>>>>>>         result[k] = proxy
>>>>>>     return result
       
       
    1: def unpack_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:
           """Inverts the transform performed by `build_lenient_weakvaluedict`."""
    3:     if d is None:
    3:         return None
       
>>>>>>     result = {}
>>>>>>     for k, v in d.items():
>>>>>>         if isinstance(v, _PydanticWeakRef):
>>>>>>             v = v()
>>>>>>             if v is not None:
>>>>>>                 result[k] = v
               else:
>>>>>>             result[k] = v
>>>>>>     return result
       
       
    2: @cache
    2: def default_ignored_types() -> tuple[type[Any], ...]:
    1:     from ..fields import ComputedFieldInfo
       
    1:     ignored_types = [
    1:         FunctionType,
    1:         property,
    1:         classmethod,
    1:         staticmethod,
    1:         PydanticDescriptorProxy,
    1:         ComputedFieldInfo,
    1:         TypeAliasType,  # from `typing_extensions`
           ]
       
    1:     if sys.version_info >= (3, 12):
    1:         ignored_types.append(typing.TypeAliasType)
       
    1:     return tuple(ignored_types)
